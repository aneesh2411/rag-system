# Docker Compose for Hybrid RunPod Setup
# This configuration runs API and UI locally while using RunPod for ES and LLM

services:
  api:
    build:
      context: .
      dockerfile: Dockerfile.api
    container_name: rag-api-runpod
    environment:
      # Elasticsearch Configuration
      - ELASTICSEARCH_URL=${ELASTICSEARCH_URL}
      
      # LLM Configuration
      - OPENAI_BASE_URL=${OPENAI_BASE_URL}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=${OPENAI_MODEL}
      - LLM_PROVIDER=${LLM_PROVIDER}
      
      # Performance optimizations
      - TOKENIZERS_PARALLELISM=false
      
      # Google Drive (optional)
      - DRIVE_FOLDER_ID=${DRIVE_FOLDER_ID}
    ports:
      - "8000:8000"
    volumes:
      - ./docs:/app/docs
      - ./.env:/app/.env  # Mount environment file
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 1G
          cpus: '0.5'
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8000/healthz || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  ui:
    build:
      context: .
      dockerfile: Dockerfile.ui
    container_name: rag-ui-runpod
    environment:
      - API_URL=http://api:8000
    ports:
      - "8501:8501"
    depends_on:
      api:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8501/_stcore/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

# Note: No volumes needed since we're using RunPod for data persistence
